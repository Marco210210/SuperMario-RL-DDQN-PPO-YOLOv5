# Super Mario Bros AI Agent ğŸ®ğŸ§ 

This project explores the application of **Reinforcement Learning (RL)** and **Computer Vision** techniques to train an agent capable of completing a level of the classic *Super Mario Bros* game. It was developed for the Artificial Intelligence course at the University of Salerno.

---

## ğŸ“Œ Project Summary

Three main approaches were tested:

1. **DDQN** (Deep Double Q-Network)
2. **PPO** (Proximal Policy Optimization) with different configurations
3. **PPO + YOLOv5** integration for object detection

The agent was trained to complete the level `SuperMarioBros-1-1-v0` using `gym-super-mario-bros`.

---

## ğŸ§  Objectives

- Train an agent to autonomously complete a level of Super Mario Bros
- Compare RL models (DDQN vs PPO)
- Improve vision-based decisions with **YOLOv5** object detection
- Analyze performance through metrics like reward, Q-values, and policy loss

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ docs/                       # Project documentation
â”‚   â”œâ”€â”€ Traccia.pdf             # Project prompt
â”‚   â”œâ”€â”€ Relazione Super Mario Bros.pdf   # Final report
â”‚   â””â”€â”€ Presentazione Super Mario.pptx   # Presentation slides
â”‚
â”œâ”€â”€ media/                      # Output media
â”‚   â”œâ”€â”€ completo.mp4            # Full run demo
â”‚   â””â”€â”€ Vittoria_Mario.mp4      # Winning episode clip âœ…
â”‚
â”œâ”€â”€ prog/                       # Code and notebooks
â”‚   â”œâ”€â”€ ddqn_agent.py           # DDQN implementation (PyTorch)
â”‚   â”œâ”€â”€ ppo_512_batch.ipynb     # PPO with 512 steps
â”‚   â”œâ”€â”€ ppo_2048_batch.ipynb    # PPO with 2048 steps
â”‚   â”œâ”€â”€ ppo_with_yolo.ipynb    # PPO + YOLOv5 integration
â”‚   â””â”€â”€ mario_env/              # Ignored virtual environment
â”‚
â”œâ”€â”€ .gitignore                  # Excludes `mario_env`
â””â”€â”€ README.md                   # You're here
```

---

## ğŸ› ï¸ Technologies Used

- Python 3, PyTorch, OpenCV
- Stable-Baselines3 (PPO)
- YOLOv5 (Roboflow + Ultralytics)
- gym-super-mario-bros
- Custom wrappers (frame stack, reward shaping)

---

## ğŸ¯ Key Results

| Model           | Victories         | Notes |
|----------------|-------------------|-------|
| DDQN           | 1/1000 episodes   | High stability |
| PPO (512 steps)| 54/10M steps      | Best result overall |
| PPO (2048)     | 0                 | Failed to converge |
| PPO + YOLOv5   | 0                 | Better perception, poor translation to actions |

YOLOv5 achieved **94.2% precision** and **100% recall**, but the integrated agent still failed to win due to difficulty performing complex jumps.

---

## ğŸ® Gameplay Demo

<p align="center">
    <img src="https://github.com/Marco210210/SuperMario-RL-DDQN-PPO-YOLOv5/blob/main/media/Demo_Mario.gif" width="400">
</p>

---

## ğŸ¥ Demo Video

Watch the agent win!  
ğŸ“¹ [Victory Clip](media/Vittoria_Mario.mp4)

Or check the full episode:  
ğŸ“º [Full Demo](media/completo.mp4)

---

## ğŸ“Œ Notes

- This project required significant hardware resources (GPU for training PPO/YOLOv5).
- Training time: ~48h for PPO + YOLOv5 on Mac without GPU.
- All models trained on `SuperMarioBros-1-1-v0`.

---

## ğŸ‘¥ Authors

- Giovanni Arcangeli  
- Vittorio Ciancio  
- Marco Di Maio  

---

## ğŸ“¬ Contact

For questions or feedback, feel free to reach out via GitHub or email.

